# awesome-scalable-gnn and knowledge distillation
Papers about scalable Graph Neural Networks (GNNs) and Knowledge Distilition.
If you feel there are papers with related topics missing, do not hesitate to let us know (via issues or pull requests).

# Scalable-GNN
1. [Neurips 2017] **Inductive Representation Learning on Large Graphs** [[paper]](https://arxiv.org/abs/1706.02216)[[code]](https://github.com/williamleif/GraphSAGE)
2. [ICLR 2020] **GraphSAINT: Graph Sampling Based Inductive Learning Method** [[paper]](https://arxiv.org/abs/1907.04931)[[code]](https://github.com/GraphSAINT/GraphSAINT)
3. [Arxiv 2021] **Accelerating Large Scale Real-Time GNN Inference using Channel Pruning** [[paper]](https://arxiv.org/abs/2105.04528)[[code]](https://github.com/tedzhouhk/GCNP)
4. [KDD 2020] **Scaling Graph Neural Networks with Approximate PageRank**[[paper]](https://arxiv.org/abs/2007.01570)[[code]](https://github.com/TUM-DAML/pprgo_pytorch)
5. [ICLR 2018] **FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling**[[paper]](https://arxiv.org/abs/1801.10247)[[code]](https://github.com/matenure/FastGCN)
6. [ICML 2018] **Stochastic Training of Graph Convolutional Networks with Variance Reduction**[[paper]](https://arxiv.org/abs/1710.10568)
7. [Neurips 2018] **Adaptive Sampling Towards Fast Graph Representation Learning**[[paper]](https://arxiv.org/abs/1809.05343)
8. [KDD 2019] **Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks**[[paper]](https://arxiv.org/abs/1905.07953)[[code]](https://github.com/google-research/google-research)
9. [KDD 2018] **Large-Scale Learnable Graph Convolutional Networks**[[paper]](https://dl.acm.org/doi/abs/10.1145/3219819.3219947)[[code]](https://github.com/divelab/lgcn)
10. [Arxiv 2021] **DistGNN: Scalable Distributed Training for Large-Scale Graph Neural Networks**[[paper]](https://arxiv.org/abs/2104.06700)[[code]]()
11. [Arxiv 2018] **Towards Efficient Large-Scale Graph Neural Network Computing**[[paper]](https://arxiv.org/pdf/1810.08403.pdf)
12. [ICML 2021] **GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings**[[paper]](https://arxiv.org/pdf/2106.05609.pdf)[[code]](https://github.com/rusty1s/pyg_autoscale)
13. [KDD Cup 2021] **OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs**[[paper]](https://arxiv.org/pdf/2103.09430.pdf)[[code]](https://github.com/snap-stanford/ogb)
14. [KDD 2018] **Graph Convolutional Neural Networks for Web-Scale Recommender Systems** [[paper]](https://arxiv.org/abs/1806.01973)[[code]](https://github.com/yoonjong12/pinsage)

# Knowledge Distillation
1. [CVPR 2020] **Distilling Knowledge from Graph Convolutional Networks** [[paper]](https://arxiv.org/abs/2003.10477)[[code]](https://github.com/ihollywhy/DistillGCN.PyTorch)
2. [IJCAI 2021] **Graph-Free Knowledge Distillation for Graph Neural Networks** [[paper]](https://arxiv.org/pdf/2105.07519.pdf)[[code]](https://github.com/Xiang-Deng-DL/GFKD)
3. [International Journal of Computer Vision] **Knowledge Distillation: A Survey** [[paper]](https://arxiv.org/pdf/2006.05525.pdf)
